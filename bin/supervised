#!/usr/bin/env python
"""Start supervised training from PGN file or saved dataset"""
from dinora.utils import disable_tensorflow_log

disable_tensorflow_log()

import argparse

import numpy as np
from tensorflow import keras
import tensorflow as tf

from dinora.model import build_model, LightConfig
from dinora.dataset import create_dataset_from_pgn
from dinora.keras_utils import TimeCallback


parser = argparse.ArgumentParser(description="This program starts supervised training")
parser.add_argument("dataset_path")
parser.add_argument("--hours", type=int)
parser.add_argument("--max_games", type=int)

args = parser.parse_args()

print("Imports complete")


model = build_model(LightConfig)
model.compile(
    keras.optimizers.Adam(),
    loss=["categorical_crossentropy", "mean_squared_error"],
    metrics=["accuracy"],
)


if args.dataset_path.endswith(".tfdataset"):
    dataset = tf.data.experimental.load(args.dataset_path, compression="GZIP")
elif args.dataset_path.endswith(".pgn"):
    dataset = create_dataset_from_pgn(args.dataset_path, args.max_games)
elif args.dataset_path.endswith(".npz"):
    data = np.load(args.dataset_path)
    dataset = tf.data.Dataset.from_tensor_slices(
        (data["planes"], (data["policies"], data["results"]))
    ).map(
        lambda planes, policy_result: (
            tf.cast(planes, tf.float32),
            (
                tf.cast(policy_result[0], tf.float32),
                tf.cast(policy_result[1], tf.float32),
            ),
        )
    )


dataset = dataset.batch(512).prefetch(tf.data.AUTOTUNE)

print("Dataset loaded")

callbacks = []

if args.hours:
    callbacks.append(TimeCallback(args.hours))

model.fit(dataset, epochs=1, callbacks=callbacks)
print("Complete")
